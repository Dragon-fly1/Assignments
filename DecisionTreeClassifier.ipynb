{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d82f13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a6648b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self,feature_val=None,threshold=None,info_gain=None,left_child=None,right_child=None,value=None):\n",
    "        \n",
    "        #if it is a decision node\n",
    "        self.feature_val = feature_val\n",
    "        self.threshold = threshold\n",
    "        self.info_gain = info_gain\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "\n",
    "        #if it is leaf node\n",
    "        self.value = value\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self,min_sample_split,max_depth):\n",
    "        self.root = None\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def build_tree(self,X,y,cur_depth=0):\n",
    "        num_samples,num_features = np.shape(X)\n",
    "        if num_samples>=self.min_sample_split and cur_depth<self.max_depth:\n",
    "            best_split = self.get_best_split(X,y)\n",
    "            #print(best_split)\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                left_subtree = self.build_tree(best_split[\"left_data_X\"],best_split[\"left_data_y\"],cur_depth+1)\n",
    "                right_subtree = self.build_tree(best_split[\"right_data_X\"],best_split[\"right_data_y\"],cur_depth+1)\n",
    "                return node(best_split[\"feature_val\"],best_split[\"threshold\"],best_split[\"info_gain\"],left_subtree,right_subtree)\n",
    "            \n",
    "        leaf_node_value = self.get_leaf_node_value(y)\n",
    "        return node(value=leaf_node_value)\n",
    "    \n",
    "    def get_best_split(self,X,y):\n",
    "        best_split = {}\n",
    "        max_ig = -1\n",
    "        for feature in X:\n",
    "            feature_values = np.unique(X[feature])\n",
    "            for threshold in feature_values:\n",
    "                left_X,left_y,right_X,right_y = self.split(X,y,feature,threshold)\n",
    "                if len(left_X)>0 and len(right_X)>0:\n",
    "                    cur_ig = self.ig(y,left_y,right_y)\n",
    "                    if cur_ig>max_ig:\n",
    "                        best_split[\"feature_val\"] = feature\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"left_data_X\"] = left_X\n",
    "                        best_split[\"left_data_y\"] = left_y\n",
    "                        best_split[\"right_data_X\"] = right_X\n",
    "                        best_split[\"right_data_y\"] = right_y\n",
    "                        best_split[\"info_gain\"] = cur_ig\n",
    "                        max_ig = cur_ig\n",
    "        return best_split\n",
    "\n",
    "    def split(self,X,y,feature,threshold):\n",
    "        left_X,left_y = X[X[feature]<=threshold],y[X[feature]<=threshold]\n",
    "        right_X,right_y = X[X[feature]>threshold],y[X[feature]>threshold]\n",
    "        return left_X,left_y,right_X,right_y\n",
    "    \n",
    "    def ig(self,y,left_y,right_y,type=\"entropy\"):\n",
    "        left_weight = len(left_y)/len(y)\n",
    "        right_weight = len(right_y)/len(y)\n",
    "\n",
    "        if type==\"gini\":\n",
    "            gain = self.gini_index(y) - (left_weight*self.gini_index(left_y) + right_weight*self.gini_index(right_y))\n",
    "        else:\n",
    "            gain = self.entropy(y) - (left_weight*self.entropy(left_y) + right_weight*self.entropy(right_y))\n",
    "        return gain\n",
    "    \n",
    "    def get_leaf_node_value(self,y):\n",
    "        return max(list(y),key=list(y).count)\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.root = self.build_tree(X,y)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        def make_prediction(x,tree):\n",
    "            if tree.value!=None: return tree.value     #if its a leaf node\n",
    "            \n",
    "            if x[tree.feature_val]<=tree.threshold:\n",
    "                return make_prediction(x,tree.left_child)\n",
    "            else:\n",
    "                return make_prediction(x,tree.right_child)\n",
    "\n",
    "        preditions = [make_prediction(row, self.root) for _, row in X.iterrows()]\n",
    "        return preditions\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        ''' function to compute entropy '''\n",
    "        \n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "            #print(\"here\",entropy)\n",
    "        return entropy\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        ''' function to compute gini index '''\n",
    "        \n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "\n",
    "    def print_tree(self,tree=None,indent='  '):\n",
    "        if tree==None:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(\"->class\",tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_val), \"<=\", tree.threshold, \"IG:\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left_child, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right_child, indent + indent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7f78e25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 <= 1.9 IG: 0.8753918540610234\n",
      "  left:->class 0\n",
      "  right:X_2 <= 4.7 IG: 0.6162473297052657\n",
      "    left:X_3 <= 1.5 IG: 0.19590927087360493\n",
      "        left:->class 1\n",
      "        right:->class 2\n",
      "    right:X_2 <= 5.1 IG: 0.19898180858936654\n",
      "        left:X_3 <= 1.7 IG: 0.24902249956730627\n",
      "                left:X_1 <= 2.2 IG: 0.31668908831502096\n",
      "                                left:->class 2\n",
      "                                right:->class 1\n",
      "                right:X_1 <= 3.0 IG: 0.5032583347756457\n",
      "                                left:->class 2\n",
      "                                right:->class 1\n",
      "        right:->class 2\n",
      "Accuracy: 0.9111111111111111\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.85      0.85      0.85        13\n",
      "           2       0.85      0.85      0.85        13\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.90      0.90      0.90        45\n",
      "weighted avg       0.91      0.91      0.91        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "tree = DecisionTreeClassifier(2,5)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "tree.print_tree()\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
